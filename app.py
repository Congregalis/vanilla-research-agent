import streamlit as st
import json
from datetime import datetime
import os
from nodes import (
    ReportStructureNode, 
    FirstSearchNode, 
    FirstSummaryNode, 
    ReflectionNode, 
    ReflectionSummaryNode, 
    ReportFormattingNode
)
from state import State
from tools import tavily_search
from utils import update_state_with_search_results
from llms import GeminiLLM, ZhipuAILLM
from config import (
    GEMINI_API_KEY, 
    NUM_REFLECTIONS, 
    NUM_RESULTS_PER_SEARCH, 
    CAP_SEARCH_LENGTH
)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AI Research Assistant",
    page_icon="ğŸ”",
    layout="wide"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'state' not in st.session_state:
    st.session_state.state = State()
if 'current_step' not in st.session_state:
    st.session_state.current_step = 0
if 'final_report' not in st.session_state:
    st.session_state.final_report = None

# å¸¸é‡è®¾ç½®
# NUM_REFLECTIONS = 2
# NUM_RESULTS_PER_SEARCH = 3
# CAP_SEARCH_LENGTH = 20000

# ä¸»æ ‡é¢˜
st.title("ğŸ¤– AI æ·±åº¦ç ”ç©¶åŠ©æ‰‹")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("é…ç½®")
    api_key = st.text_input("Gemini API Key", value=GEMINI_API_KEY, type="password")
    topic = st.text_input("ç ”ç©¶ä¸»é¢˜", value="2025å¹´AIè¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ")
    
    if st.button("å¼€å§‹ç ”ç©¶", type="primary"):
        st.session_state.current_step = 1
        st.session_state.state = State()
        
        # åˆå§‹åŒ– LLM
        llm_client = GeminiLLM(api_key)
        
        # åˆ›å»ºæŠ¥å‘Šç»“æ„
        with st.spinner("æ­£åœ¨ç”ŸæˆæŠ¥å‘Šç»“æ„..."):
            report_structure_node = ReportStructureNode(llm_client, topic)
            _ = report_structure_node.mutate_state(st.session_state.state)
            st.success("æŠ¥å‘Šç»“æ„å·²ç”Ÿæˆï¼")

# ä¸»è¦å†…å®¹åŒºåŸŸ
if st.session_state.current_step >= 1:
    # å…ˆå±•ç¤ºå®Œæ•´çš„æŠ¥å‘Šç»“æ„
    st.header("ğŸ“‹ å®Œæ•´æŠ¥å‘Šç»“æ„")
    with st.expander("æŸ¥çœ‹å®Œæ•´æŠ¥å‘Šç»“æ„", expanded=True):
        for idx, paragraph in enumerate(st.session_state.state.paragraphs, 1):
            st.markdown(f"""
            ### ç¬¬ {idx} éƒ¨åˆ†ï¼š{paragraph.title}
            <div style="font-size: 1rem; margin-left: 1rem;">
            {paragraph.content}
            </div>
            ---
            """, unsafe_allow_html=True)
    
    # è¯¦ç»†ç ”ç©¶è¿‡ç¨‹
    st.header("ğŸ“‘ è¯¦ç»†ç ”ç©¶è¿‡ç¨‹")
    for idx, paragraph in enumerate(st.session_state.state.paragraphs, 1):
        st.subheader(f"æ®µè½ {idx}: {paragraph.title}")
        
        # ä¸ºæ¯ä¸ªæ®µè½åˆ›å»ºä¸€ä¸ªå±•å¼€åŒºåŸŸ
        with st.expander(f"æŸ¥çœ‹æ®µè½ {idx} çš„ç ”ç©¶è¿‡ç¨‹", expanded=True):
            llm_client = GeminiLLM(api_key)
            
            # åˆå§‹åŒ–èŠ‚ç‚¹
            first_search_node = FirstSearchNode(llm_client)
            first_summary_node = FirstSummaryNode(llm_client)
            reflection_node = ReflectionNode(llm_client)
            reflection_summary_node = ReflectionSummaryNode(llm_client)
            
            # ç¬¬ä¸€æ¬¡æœç´¢
            st.write("ğŸ” **åˆå§‹æœç´¢**")
            message = json.dumps({
                "title": paragraph.title,
                "content": paragraph.content
            })
            
            with st.spinner("æ­£åœ¨è¿›è¡Œåˆå§‹æœç´¢..."):
                output = first_search_node.run(message)
                st.write("æœç´¢æŸ¥è¯¢:", output.get("search_query"))
                st.write("æ¨ç†è¿‡ç¨‹:", output.get("reasoning"))
                
                search_results = tavily_search(output.get("search_query"), max_results=NUM_RESULTS_PER_SEARCH)
                
                # ä½¿ç”¨ columns æ›¿ä»£åµŒå¥—çš„ expander
                st.write("**æœç´¢ç»“æœ:**")
                for i, result in enumerate(search_results, 1):
                    with st.container():
                        st.markdown(f"""
                        <div style="font-size: 0.9rem; margin-left: 1rem;">
                        <strong>ç»“æœ {i}:</strong><br/>
                        ğŸ“Œ <strong>æ ‡é¢˜:</strong> {result['title']}<br/>
                        ğŸ”— <strong>é“¾æ¥:</strong> {result['url']}<br/>
                        ğŸ“ <strong>æ‘˜è¦:</strong> {result['content'][:200]}...
                        </div>
                        ---
                        """, unsafe_allow_html=True)
                
                _ = update_state_with_search_results(search_results, idx-1, st.session_state.state)
            
            # åˆå§‹æ€»ç»“
            st.write("ğŸ“ **åˆå§‹æ€»ç»“**")
            message = {
                "title": paragraph.title,
                "content": paragraph.content,
                "search_query": output.get("search_query"),
                "search_results": [result["content"][0:CAP_SEARCH_LENGTH] for result in search_results if result["content"]]
            }
            
            with st.spinner("æ­£åœ¨ç”Ÿæˆåˆå§‹æ€»ç»“..."):
                _ = first_summary_node.mutate_state(message=json.dumps(message, ensure_ascii=False), idx_paragraph=idx-1, state=st.session_state.state)
                summary = st.session_state.state.paragraphs[idx-1].research.latest_summary
                if isinstance(summary, str):
                    st.markdown(f"""
                    <div style="font-size: 0.95rem; margin-left: 1rem; background-color: #f0f2f6; padding: 1rem; border-radius: 0.5rem;">
                    {summary}
                    </div>
                    """, unsafe_allow_html=True)
                elif isinstance(summary, dict) and "paragraph_latest_state" in summary:
                    st.markdown(f"""
                    <div style="font-size: 0.95rem; margin-left: 1rem; background-color: #f0f2f6; padding: 1rem; border-radius: 0.5rem;">
                    {summary["paragraph_latest_state"]}
                    </div>
                    """, unsafe_allow_html=True)
            st.write(st.session_state.state.paragraphs[idx-1].research.latest_summary)
            
            # åæ€é˜¶æ®µ
            for i in range(NUM_REFLECTIONS):
                st.write(f"ğŸ¤” **åæ€ {i+1}**")
                
                message = {
                    "paragraph_latest_state": st.session_state.state.paragraphs[idx-1].research.latest_summary,
                    "title": paragraph.title,
                    "content": paragraph.content
                }
                
                with st.spinner(f"æ­£åœ¨è¿›è¡Œç¬¬ {i+1} æ¬¡åæ€..."):
                    output = reflection_node.run(message=json.dumps(message))
                    st.write(f"åæ€æœç´¢æŸ¥è¯¢:", output.get("search_query"))
                    st.write(f"åæ€æ¨ç†:", output.get("reasoning"))
                    
                    search_results = tavily_search(output.get("search_query"))
                    st.write(f"**åæ€ {i+1} çš„æœç´¢ç»“æœ:**")
                    for j, result in enumerate(search_results, 1):
                        with st.container():
                            st.markdown(f"""
                            <div style="font-size: 0.9rem; margin-left: 1rem;">
                            <strong>ç»“æœ {j}:</strong><br/>
                            ğŸ“Œ <strong>æ ‡é¢˜:</strong> {result['title']}<br/>
                            ğŸ”— <strong>é“¾æ¥:</strong> {result['url']}<br/>
                            ğŸ“ <strong>æ‘˜è¦:</strong> {result['content'][:200]}...
                            </div>
                            ---
                            """, unsafe_allow_html=True)
                    
                    _ = update_state_with_search_results(search_results, idx-1, st.session_state.state)
                    
                    message = {
                        "title": paragraph.title,
                        "content": paragraph.content,
                        "search_query": output.get("search_query"),
                        "search_results": [result["content"][0:20000] for result in search_results if result["content"]],
                        "paragraph_latest_state": st.session_state.state.paragraphs[idx-1].research.latest_summary
                    }
                    
                    _ = reflection_summary_node.mutate_state(message=json.dumps(message, ensure_ascii=False), idx_paragraph=idx-1, state=st.session_state.state)
                    st.write("åæ€åçš„æ€»ç»“:")
                    st.write(st.session_state.state.paragraphs[idx-1].research.latest_summary)

    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    st.header("ğŸ“Š æœ€ç»ˆæŠ¥å‘Š")
    report_formatting_node = ReportFormattingNode(llm_client)
    report_data = [{"title": paragraph.title, "paragraph_latest_state": paragraph.research.latest_summary} 
                  for paragraph in st.session_state.state.paragraphs]
    
    with st.spinner("æ­£åœ¨ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š..."):
        final_report = report_formatting_node.run(json.dumps(report_data))
        st.session_state.final_report = final_report
        st.markdown(final_report)
        
        # ä¿å­˜æŠ¥å‘Š
        os.makedirs("reports", exist_ok=True)
        report_path = f"reports/report_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.md"
        with open(report_path, "w", encoding="utf-8") as f:
            f.write(final_report)
        
        st.success(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")